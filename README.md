# NLP Paper Review
NLP 논문을 리뷰하고 공부한 내용을 정리하였습니다.
## 1. Transformer
[Attention Is All You Need (NIPS 2017)](https://github.com/hngyb/NLP-Paper-Review/tree/master/Transformer)
## 2. GPT
[Improving Language Understanding by Generative Pre-Training](https://github.com/hngyb/NLP-Paper-Review/tree/master/GPT)
## 3. BERT
[BERT- Pre-training of Deep Bidirectional Transformers for Language Understanding](https://github.com/hngyb/NLP-Paper-Review/tree/master/BERT)
